**决策树**（decision tree）是一种基本的分类与回归方法

决策树通常有**三个步骤**：特征选择、决策树的生成、决策树的修剪。

**分类方法**：从根节点开始，对实例的某一特征进行测试，根据测试结果将实例分配到其子节点，此时每个子节点对应着该特征的一个取值，如此递归的对实例进行测试并分配，直到到达叶节点，最后将实例分到叶节点的类中。

- 决策树学习的目标： 根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。
- 决策树学习的本质： 从训练集中归纳出一组分类规则，或者说是由训练数据集估计条件概率模型。
- 决策树学习的损失函数： 正则化的极大似然函数
- 决策树学习的测试： 最小化损失函数
- 决策树学习的目标： 在损失函数的意义下，选择最优决策树的问题。
