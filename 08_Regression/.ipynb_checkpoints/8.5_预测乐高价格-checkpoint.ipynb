{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(xMat): #regularize by columns\n",
    "    inMat = xMat.copy()\n",
    "    inMeans = np.mean(inMat,0) #计算平均数，然后减去它\n",
    "    inVar = np.var(inMat,0)\n",
    "    inMat = (inMat-inMeans)/inVar\n",
    "    return inMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算最佳拟合直线\n",
    "$w'=\\left(X^TX\\right)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standRegres(xArr, yArr):\n",
    "    xMat = np.mat(xArr)\n",
    "    yMat = np.mat(yArr).T\n",
    "    xTx = xMat.T * xMat\n",
    "    if np.linalg.det(xTx) == 0.0:    # 判断行列式是否为0\n",
    "        print('This matrix is singular, cannot do inverse.')\n",
    "        return\n",
    "    ws = xTx.I * (xMat.T * yMat)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 局部加权线性回归函数\n",
    "$w'=\\left(X^TWX\\right)^{-1}X^TWy$  \n",
    "高斯核：  \n",
    "$w\\left(i,i\\right)=exp\\left(\\frac{\\left|x^{(i)}-x\\right|}{-2k^2}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lwlr(testPoint, xArr, yArr, k=1.0):\n",
    "    xMat = np.mat(xArr)\n",
    "    yMat = np.mat(yArr).T\n",
    "    m = np.shape(xMat)[0]\n",
    "    weights = np.mat(np.eye((m)))    # 创建对角矩阵\n",
    "    # 样本点与代预测点距离越远，权重以指数级衰减，k控制衰减速度\n",
    "    for j in range(m):\n",
    "        diffMat = testPoint - xMat[j, :]\n",
    "        weights[j, j] = np.exp(diffMat * diffMat.T / (-2.0 * k ** 2))\n",
    "    xTx = xMat.T * (weights * xMat)\n",
    "    if np.linalg.det(xTx) == 0.0:    # 判断行列式是否为0\n",
    "        print('This matrix is singular, cannot do inverse.')\n",
    "        return\n",
    "    ws = xTx.I * (xMat.T * (weights * yMat))\n",
    "    return testPoint * ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为数据集中每个点调用lwlr()\n",
    "def lwlrTest(testArr, xArr, yArr, k=1.0):\n",
    "    m = np.shape(testArr)[0]\n",
    "    yHat = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        yHat[i] = lwlr(testArr[i], xArr, yArr, k)\n",
    "    return yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rssError(yArr, yHatArr):\n",
    "    return ((yArr - yHatArr)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 岭回归（ridge regression）  \n",
    "在矩阵$X^TX$上加一个$\\lambda I$从而使得矩阵非奇异，进而能对$X^TX+\\lambda I$求逆。  \n",
    "回归系数的计算公式将变成：  \n",
    "$w'=\\left(X^TX+\\lambda I\\right)^{-1}X^Ty$  \n",
    "约束条件：  \n",
    "$\\sum_{k=1}^nw_k^2\\leq\\lambda$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算回归系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeRegres(xMat, yMat, lam=0.2):\n",
    "    xTx = xMat.T * xMat\n",
    "    denom = xTx + np.eye(np.shape(xMat)[1]) * lam\n",
    "    if np.linalg.det(denom) == 0.0:    # 判断行列式是否为0\n",
    "        print('This matrix is singular, cannot do inverse.')\n",
    "        return\n",
    "    ws = denom.I * (xMat.T * yMat)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeTest(xArr, yArr):\n",
    "    xMat = np.mat(xArr)\n",
    "    yMat = np.mat(yArr).T\n",
    "    yMean = np.mean(yMat, 0)\n",
    "    # 数据标准化\n",
    "    yMat = yMat - yMean\n",
    "    xMeans = np.mean(xMat,0)\n",
    "    xVar = np.var(xMat, 0)\n",
    "    xMat = (xMat - xMeans) / xVar    # 减去均值，除以方差\n",
    "    numTestPts = 30\n",
    "    wMat = np.zeros((numTestPts, np.shape(xMat)[1]))\n",
    "    for i in range(numTestPts):\n",
    "        ws = ridgeRegres(xMat, yMat, np.exp(i-10))\n",
    "        wMat[i,:] = ws.T\n",
    "    return wMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lasso\n",
    "约束条件：  \n",
    "$\\sum_{k=1}^n\\left|w_k\\right|\\leq\\lambda$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向逐步回归  \n",
    "伪代码：  \n",
    "数据标准化，使其分布满足0均值和单位方差  \n",
    "在美轮迭代过程中：  \n",
    "&ensp;&ensp;&ensp;&ensp;设置当前最小误差lowestError为正无穷  \n",
    "&ensp;&ensp;&ensp;&ensp;对每个特征：  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;增大或缩小  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;改变一个系数得到一个新的W  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;计算新W下的误差  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;如果误差Error小于当前最小误差lowestError：  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;设置Wbest等于当前W  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;将W设为新的Wbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stageWise(xArr, yArr, eps=0.01, numIt=100):    # eps:每次迭代调整的步长\n",
    "    xMat = np.mat(xArr)\n",
    "    yMat = np.mat(yArr).T\n",
    "    yMean = np.mean(yMat, 0)\n",
    "    yMat = yMat - yMean\n",
    "    xMat = regularize(xMat)\n",
    "    m, n = np.shape(xMat)\n",
    "    returnMat = np.zeros((numIt, n))\n",
    "    ws = np.zeros((n, 1))\n",
    "    wsTest = ws.copy()\n",
    "    wsMax = ws.copy()\n",
    "    for i in range(numIt):\n",
    "        print(ws.T)\n",
    "        lowestError = np.inf\n",
    "        for j in range(n):\n",
    "            for sign in [-1, 1]:\n",
    "                wsTest = ws.copy()\n",
    "                wsTest[j] += eps * sign\n",
    "                yTest = xMat * wsTest\n",
    "                rssE = rssError(yMat.A, yTest.A)\n",
    "                if rssE < lowestError:\n",
    "                    lowestError = rssE\n",
    "                    wsMax = wsTest\n",
    "        ws = wsMax.copy()\n",
    "        returnMat[i, :] = ws.T\n",
    "    return returnMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForSet(retX, retY, setNum, yr, numPce, origPrc):\n",
    "    sleep(10)\n",
    "    myAPIstr = 'AIzaSyD2cR2KFyx12hXu6PFU-wrWot3NXvko8vY'\n",
    "    searchURL = 'https://www.googleapis.com/shopping/search/v1/public/products?key=%s&country=US&q=lego+%d&alt=json' % (myAPIstr, setNum)\n",
    "    pg = urllib.request.urlopen(searchURL)\n",
    "    retDict = json.loads(pg.read())\n",
    "    for i in range(len(retDict['items'])):\n",
    "        try:\n",
    "            currItem = retDict['items'][i]\n",
    "            if currItem['product']['condition'] == 'new':\n",
    "                newFlag = 1\n",
    "            else: newFlag = 0\n",
    "            listOfInv = currItem['product']['inventories']\n",
    "            for item in listOfInv:\n",
    "                sellingPrice = item['price']\n",
    "                if  sellingPrice > origPrc * 0.5:\n",
    "                    print(\"%d\\t%d\\t%d\\t%f\\t%f\" % (yr,numPce,newFlag,origPrc, sellingPrice))\n",
    "                    retX.append([yr, numPce, newFlag, origPrc])\n",
    "                    retY.append(sellingPrice)\n",
    "        except: \n",
    "            print('problem with item %d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDataCollect(retX, retY):\n",
    "    searchForSet(retX, retY, 8288, 2006, 800, 49.99)\n",
    "    searchForSet(retX, retY, 10030, 2002, 3096, 269.99)\n",
    "    searchForSet(retX, retY, 10179, 2007, 5195, 499.99)\n",
    "    searchForSet(retX, retY, 10181, 2007, 3428, 199.99)\n",
    "    searchForSet(retX, retY, 10189, 2008, 5922, 299.99)\n",
    "    searchForSet(retX, retY, 10196, 2009, 3263, 249.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证测试岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(xArr,yArr,numVal=10):\n",
    "    m = len(yArr)                           \n",
    "    indexList = range(m)\n",
    "    errorMat = np.zeros((numVal, 30))#create error mat 30columns numVal rows\n",
    "    for i in range(numVal):\n",
    "        trainX = []\n",
    "        trainY = []\n",
    "        testX = []\n",
    "        testY = []\n",
    "        np.random.shuffle(indexList)\n",
    "        for j in range(m):#create training set based on first 90% of values in indexList\n",
    "            if j < m * 0.9: \n",
    "                trainX.append(xArr[indexList[j]])\n",
    "                trainY.append(yArr[indexList[j]])\n",
    "            else:\n",
    "                testX.append(xArr[indexList[j]])\n",
    "                testY.append(yArr[indexList[j]])\n",
    "        wMat = ridgeTest(trainX,trainY)    #get 30 weight vectors from ridge\n",
    "        for k in range(30):#loop over all of the ridge estimates\n",
    "            matTestX = np.mat(testX)\n",
    "            matTrainX = np.mat(trainX)\n",
    "            meanTrain = np.mean(matTrainX, 0)\n",
    "            varTrain = np.var(matTrainX, 0)\n",
    "            matTestX = (matTestX - meanTrain) / varTrain #regularize test with training params\n",
    "            yEst = matTestX * np.mat(wMat[k,:]).T + np.mean(trainY)#test ridge results and store\n",
    "            errorMat[i,k] = rssError(yEst.T.A, np.array(testY))\n",
    "            #print errorMat[i,k]\n",
    "    meanErrors = np.mean(errorMat,0)#calc avg performance of the different ridge weight vectors\n",
    "    minMean = float(min(meanErrors))\n",
    "    bestWeights = wMat[nonzero(meanErrors == minMean)]\n",
    "    #can unregularize to get model\n",
    "    #when we regularized we wrote Xreg = (x-meanX)/var(x)\n",
    "    #we can now write in terms of x not Xreg:  x*w/var(x) - meanX/var(x) +meanY\n",
    "    xMat = np.mat(xArr)\n",
    "    yMat = np.mat(yArr).T\n",
    "    meanX = np.mean(xMat, 0)\n",
    "    varX = np.var(xMat, 0)\n",
    "    unReg = bestWeights / varX\n",
    "    print(\"the best model from Ridge Regression is:\\n\", unReg)\n",
    "    print(\"with constant term: \", -1*sum(multiply(meanX,unReg)) + mean(yMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
