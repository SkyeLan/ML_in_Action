{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(currLine[-1]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于单层决策树构建弱分类器  \n",
    "伪代码：  \n",
    "将最小错误率minError设为+∞  \n",
    "对数据集中的每一个特征（第一层循环）：  \n",
    "&ensp;&ensp;&ensp;&ensp;对每个步长（第二层循环）：  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;对每个不等号（第三层循环）：  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;建立一颗单层决策树并利用加权数据集对它进行测试  \n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;如果错误率低于minError，则将当前单层决策树设为最佳单层决策树  \n",
    "返回最佳单层决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过阈值比较进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal,threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0], 1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到具有最低错误率的单层决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr, classLabels, D):\n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}    # 定义空字典，存储给定D时的单层决策树信息\n",
    "    bestClassEst = np.mat(np.zeros((m, 1)))\n",
    "    minError = np.inf    # 寻找最小错误率\n",
    "    for i in range(n):    # 在数据集的所有特征上遍历\n",
    "        rangeMin = dataMatrix[:, i].min()\n",
    "        rangeMax = dataMatrix[:, i].max()\n",
    "        stepSize = (rangeMax - rangeMin)/numSteps    # 需要的步长\n",
    "        for j in range(-1, int(numSteps)+1):    # 对步长遍历\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                errArr = np.mat(np.ones((m, 1)))\n",
    "                errArr[predictedVals == labelMat] = 0    # 等则对，不等则错\n",
    "                weightedError = D.T * errArr    # 加权错误率\n",
    "                #print('split: dim %d, thresh %.2f,thresh ineqal: %s,the weighted error is %.3f' % (i,threshVal,inequal,weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClassEst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整AdaBoost算法  \n",
    "伪代码：\n",
    "对每次迭代：  \n",
    "&ensp;&ensp;&ensp;&ensp;利用buildStump()函数找到最佳的单层决策树  \n",
    "&ensp;&ensp;&ensp;&ensp;将最佳单层决策树加入到单层决策树数组  \n",
    "&ensp;&ensp;&ensp;&ensp;计算alpha  \n",
    "&ensp;&ensp;&ensp;&ensp;计算新的权重向量$D$  \n",
    "&ensp;&ensp;&ensp;&ensp;更新累计类别估计值  \n",
    "&ensp;&ensp;&ensp;&ensp;如果错误率等于0.0，则退出循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):    # numIt:迭代次数\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m, 1))/m)\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D)\n",
    "        print('D:', D.T)\n",
    "        alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        print('classEst:', classEst.T)\n",
    "        # 计算下一次迭代的D\n",
    "        expon = np.multiply(-1 * alpha * np.mat(classLabels).T, classEst)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D / D.sum()\n",
    "        aggClassEst += alpha * classEst\n",
    "        print('aggClassEst:', aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m, 1)))\n",
    "        errorRate = aggErrors.sum() / m\n",
    "        print('total error:', errorRate, '\\n')\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost分类函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass, classifierArr):\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'], classifierArr[i]['thresh'], classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha'] * classEst\n",
    "        print(aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datMat, classLabels = loadSimpData()\n",
    "D = np.mat(np.ones((5, 1))/5)\n",
    "buildStump(datMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst: [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst: [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error: 0.2 \n",
      "\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst: [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst: [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error: 0.2 \n",
      "\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst: [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst: [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error: 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifierArr = adaBoostTrainDS(datMat, classLabels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0, 0], classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n",
      "[[ 2.56198199]\n",
      " [-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([[5, 5],[0, 0]], classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
